{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EECS 731 Project 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Import relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------\n",
      "The scikit-learn version is 0.20.3.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries necessary for this project\n",
    "import os\n",
    "#import sys\n",
    "import time\n",
    "import sklearn\n",
    "#import networkx as nx\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns; sns.set()\n",
    "import datetime as dt\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from pandas import compat\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import mixture\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn import metrics\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "pd.set_option('display.max_columns', None)  # or 1000\n",
    "pd.set_option('display.max_rows', None)  # or 1000\n",
    "pd.set_option('display.max_colwidth', -1)  # or 199\n",
    "\n",
    "compat.PY3 = True\n",
    "print (\"-----------------------------------------------------------------------\")\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Pre requisite functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This function load the data from the given path and finename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to load the data\n",
    "def loadData(path,filename):\n",
    "    try:\n",
    "             files = os.listdir(path)\n",
    "             for f in files:\n",
    "                 if f == filename:\n",
    "                     data = pd.read_csv(os.path.join(path,f))\n",
    "                     return data\n",
    "            \n",
    "    except Exception as ex:\n",
    "           print (\"-----------------------------------------------------------------------\")\n",
    "           template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "           message = template.format(type(ex).__name__, ex.args)\n",
    "           print (message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This function derives the shape of the dataset and returns the feature and target columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to explore the data\n",
    "def exploreData(data):\n",
    "    try:\n",
    "           #Total number of records                                  \n",
    "           rows = data.shape[0]\n",
    "           cols = data.shape[1]    \n",
    "          \n",
    "           # Print the results\n",
    "           print (\"-----------------------------------------------------------------------\")\n",
    "           print (\"Total number of records: {}\".format(rows))\n",
    "           print (\"Total number of features: {}\".format(cols))\n",
    "           print (\"-----------------------------------------------------------------------\")\n",
    "           \n",
    "    except Exception as ex:\n",
    "           print (\"-----------------------------------------------------------------------\")\n",
    "           template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "           message = template.format(type(ex).__name__, ex.args)\n",
    "           print (message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This function computes the percentage of missing values per each column in the given dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missingValues(data):\n",
    "    try:\n",
    "           # Total missing values\n",
    "           mis_val = data.isnull().sum()\n",
    "         \n",
    "           # Percentage of missing values\n",
    "           mis_val_percent = 100 * mis_val / len(data)\n",
    "           \n",
    "           # Make a table with the results\n",
    "           mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "           \n",
    "           # Rename the columns\n",
    "           mis_val_table_ren_columns = mis_val_table.rename(\n",
    "           columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "           mis_val_table_ren_columns.head(4 )\n",
    "           # Sort the table by percentage of missing descending\n",
    "           misVal = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "                   '% of Total Values', ascending=False).round(1)\n",
    "                     \n",
    "           return misVal, mis_val_table_ren_columns\n",
    "\n",
    "    except Exception as ex:\n",
    "           print (\"-----------------------------------------------------------------------\")\n",
    "           template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "           message = template.format(type(ex).__name__, ex.args)\n",
    "           print (message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This method scale the numerical features and label encoding for categorical features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformData(df):\n",
    "    try:    \n",
    "        #Get the list of columns having negative columns from describe\n",
    "        nc = []\n",
    "        for i in df.columns:\n",
    "            if df[i].min() < 0:\n",
    "                nc.append(i)\n",
    "         \n",
    "        target = df[' shares']\n",
    "        features_transform = pd.DataFrame(data = df)\n",
    "        features_transform = features_transform.drop(columns=[' shares'], axis=1)\n",
    "        \n",
    "        #Add constant value to make the negative values as positive.\n",
    "        for i in nc:\n",
    "            minv = features_transform[i].min()\n",
    "            minv = minv * -1\n",
    "            features_transform[i] = features_transform[i] + minv\n",
    "\n",
    "        #Get the list of columns that are skew\n",
    "        sc = []\n",
    "        for i in features_transform.columns:\n",
    "            if df[i].max() > 1:\n",
    "                sc.append(i)\n",
    "                \n",
    "        #Scale the data to reduce the skewness \n",
    "#        features_transform[sc] = features_transform[sc].apply(lambda x: np.log(x + 1))\n",
    "        scaler = MinMaxScaler() # default=(0, 1)\n",
    "        features_transform[sc] = scaler.fit_transform(features_transform[sc])\n",
    "        \n",
    "        ind = np.where(target < 1400)\n",
    "        target.iloc[ind] = 1\n",
    "        \n",
    "        ind = np.where(target >=1400)\n",
    "        target.iloc[ind] = 0\n",
    "\n",
    "        return features_transform, target\n",
    "        \n",
    "    except Exception as ex:\n",
    "           print (\"-----------------------------------------------------------------------\")\n",
    "           template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "           message = template.format(type(ex).__name__, ex.args)\n",
    "           print (message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This method splits data in to training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data in to train and test data\n",
    "def splitData(features,target,testsize):\n",
    "    try:\n",
    "        # Split the 'features' and 'income' data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(features,\n",
    "                                                    target, \n",
    "                                                    test_size = testsize, \n",
    "                                                    random_state = 1)\n",
    "\n",
    "        # Show the results of the split\n",
    "        print (\"Features training set has {} samples.\".format(X_train.shape[0]))\n",
    "        print (\"Features testing set has {} samples.\".format(X_test.shape[0]))\n",
    "        print (\"Target training set has {} samples.\".format(y_train.shape[0]))\n",
    "        print (\"Target testing set has {} samples.\".format(y_test.shape[0]))\n",
    "        print (\"-----------------------------------------------------------------------\")\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    except Exception as ex:\n",
    "           print (\"-----------------------------------------------------------------------\")\n",
    "           template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "           message = template.format(type(ex).__name__, ex.args)\n",
    "           print (message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This method implements Multinomial Bayesian classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multinomialnb(X_train, X_test, y_train, y_test):\n",
    "    try:\n",
    "        #logic\n",
    "        clf = MultinomialNB()\n",
    "        params = {}\n",
    "\n",
    "        scoring_fnc = make_scorer(fbeta_score,average='micro',beta=0.5)\n",
    "        learner = GridSearchCV(clf,params,scoring=scoring_fnc)\n",
    "        results = {}\n",
    "         \n",
    "        start_time = time.clock()\n",
    "        grid = learner.fit(X_train,y_train)\n",
    "        \n",
    "        end_time = time.clock()\n",
    "        results['train_time'] = end_time - start_time\n",
    "        clf_fit_train = grid.best_estimator_\n",
    "        start_time = time.clock()\n",
    "        clf_predict_train = clf_fit_train.predict(X_train)\n",
    "        clf_predict_test = clf_fit_train.predict(X_test)\n",
    "        end_time = time.clock()\n",
    "        results['pred_time'] = end_time - start_time  \n",
    "         \n",
    "        results['acc_train'] = accuracy_score(y_train, clf_predict_train)\n",
    "        results['acc_test']  = accuracy_score(y_test, clf_predict_test)\n",
    "        results['f_train']   = fbeta_score(y_train, clf_predict_train, average='micro', beta=1)\n",
    "        results['f_test']    = fbeta_score(y_test, clf_predict_test, average='micro', beta=1.5)\n",
    "        \n",
    "        return results,clf_fit_train      \n",
    "    except Exception as ex:\n",
    "           print (\"-----------------------------------------------------------------------\")\n",
    "           template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "           message = template.format(type(ex).__name__, ex.args)\n",
    "           print (message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This method implements SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svmClassifier(X_train, X_test, y_train, y_test):\n",
    "    try:\n",
    "        #Decision tree classifier\n",
    "        #learner = DecisionTreeClassifier(criterion=method, max_depth=depth, random_state=1)\n",
    "        clf = svm.SVC(random_state=0)\n",
    "        params = {'gamma':[0.001]}\n",
    "        #params = {'criterion':['gini','entropy'], 'max_depth' : np.array([6,7,8])}\n",
    "         \n",
    "        scoring_fnc = make_scorer(fbeta_score,average='micro',beta=0.5)\n",
    "        learner = GridSearchCV(clf,params,scoring=scoring_fnc)\n",
    "        results = {}\n",
    "         \n",
    "        start_time = time.clock()\n",
    "        grid = learner.fit(X_train,y_train)\n",
    "         \n",
    "        end_time = time.clock()\n",
    "        results['train_time'] = end_time - start_time\n",
    "        clf_fit_train = grid.best_estimator_\n",
    "        start_time = time.clock()\n",
    "        clf_predict_train = clf_fit_train.predict(X_train)\n",
    "        clf_predict_test = clf_fit_train.predict(X_test)\n",
    "        end_time = time.clock()\n",
    "        results['pred_time'] = end_time - start_time  \n",
    "         \n",
    "        results['acc_train'] = accuracy_score(y_train, clf_predict_train)\n",
    "        results['acc_test']  = accuracy_score(y_test, clf_predict_test)\n",
    "        \n",
    "        return results,clf_fit_train      \n",
    "    except Exception as ex:\n",
    "           print (\"-----------------------------------------------------------------------\")\n",
    "           template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "           message = template.format(type(ex).__name__, ex.args)\n",
    "           print (message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This method implements Ramdom Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForest(X_train, X_test, y_train, y_test):\n",
    "    try:\n",
    "        clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "        #params = {}\n",
    "        params = {'criterion':['gini','entropy'], 'max_depth' : np.array([6,7,8]),'random_state': [0]}\n",
    "         \n",
    "        scoring_fnc = make_scorer(fbeta_score,average='micro',beta=0.5)\n",
    "        learner = GridSearchCV(clf,params,scoring=scoring_fnc)\n",
    "        results = {}\n",
    "         \n",
    "        start_time = time.clock()\n",
    "        grid = learner.fit(X_train,y_train)\n",
    "         \n",
    "        end_time = time.clock()\n",
    "        results['train_time'] = end_time - start_time\n",
    "        clf_fit_train = grid.best_estimator_\n",
    "        start_time = time.clock()\n",
    "        clf_predict_train = clf_fit_train.predict(X_train)\n",
    "        clf_predict_test = clf_fit_train.predict(X_test)\n",
    "        end_time = time.clock()\n",
    "        results['pred_time'] = end_time - start_time  \n",
    "         \n",
    "        results['acc_train'] = accuracy_score(y_train, clf_predict_train)\n",
    "        results['acc_test']  = accuracy_score(y_test, clf_predict_test)\n",
    "         \n",
    "        return results,clf_fit_train, \n",
    "    except Exception as ex:\n",
    "           print (\"-----------------------------------------------------------------------\")\n",
    "           template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "           message = template.format(type(ex).__name__, ex.args)\n",
    "           print (message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This method implement Principal component analyis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(features,dim):\n",
    "    try:\n",
    "        #logic\n",
    "        pca = PCA(n_components=dim)\n",
    "        pca.fit(features)\n",
    "        reduced_dim = pca.transform(features)\n",
    "        \n",
    "#        from pics import pca_results\n",
    "#        _ = pca_results(features, pca)\n",
    "        \n",
    "        dlist = [];\n",
    "        for i in range(dim):\n",
    "            s = \"D\" + str(i)\n",
    "            dlist.append(s)\n",
    "        pca_comp = pd.DataFrame(pca.components_,columns=features.columns,index = dlist)\n",
    "        pca_comp.transpose().to_csv('test.csv')\n",
    "        return reduced_dim, pca_comp\n",
    "    \n",
    "    except Exception as ex:\n",
    "           print (\"-----------------------------------------------------------------------\")\n",
    "           template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "           message = template.format(type(ex).__name__, ex.args)\n",
    "           print (message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This method implement Gaussian mixture clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gclus(reduced_data,ic):\n",
    "    try:\n",
    "        cluster =  mixture.GaussianMixture(covariance_type='spherical', init_params='kmeans',\n",
    "        max_iter=100, means_init=None, n_components=ic, n_init=1,\n",
    "        precisions_init=None, random_state=None, reg_covar=1e-06,\n",
    "        tol=0.001, verbose=0, verbose_interval=10, warm_start=False,\n",
    "        weights_init=None).fit(reduced_data)\n",
    "        \n",
    "        pred = cluster.predict(reduced_data)\n",
    "        \n",
    "        centers = np.empty(shape=(cluster.n_components, reduced_data.shape[1]))\n",
    "        for i in range(cluster.n_components):\n",
    "            density = stats.multivariate_normal(cov=cluster.covariances_[i], mean=cluster.means_[i]).logpdf(reduced_data)\n",
    "            centers[i, :] = reduced_data[np.argmax(density)]\n",
    "        score = metrics.silhouette_score(reduced_data, pred, metric='euclidean')\n",
    "        \n",
    "        return cluster, centers,score\n",
    "        \n",
    "    except Exception as ex:\n",
    "           print (\"-----------------------------------------------------------------------\")\n",
    "           template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "           message = template.format(type(ex).__name__, ex.args)\n",
    "           print (message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>% of Total Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>url</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timedelta</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_tokens_title</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_tokens_content</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_hrefs</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_imgs</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_videos</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_token_length</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_keywords</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_channel_is_lifestyle</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_channel_is_entertainment</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_channel_is_bus</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_channel_is_socmed</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_channel_is_tech</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_channel_is_world</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_min_min</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Missing Values  % of Total Values\n",
       "url                             0               0.0              \n",
       " timedelta                      0               0.0              \n",
       " n_tokens_title                 0               0.0              \n",
       " n_tokens_content               0               0.0              \n",
       " n_unique_tokens                0               0.0              \n",
       " n_non_stop_words               0               0.0              \n",
       " n_non_stop_unique_tokens       0               0.0              \n",
       " num_hrefs                      0               0.0              \n",
       " num_self_hrefs                 0               0.0              \n",
       " num_imgs                       0               0.0              \n",
       " num_videos                     0               0.0              \n",
       " average_token_length           0               0.0              \n",
       " num_keywords                   0               0.0              \n",
       " data_channel_is_lifestyle      0               0.0              \n",
       " data_channel_is_entertainment  0               0.0              \n",
       " data_channel_is_bus            0               0.0              \n",
       " data_channel_is_socmed         0               0.0              \n",
       " data_channel_is_tech           0               0.0              \n",
       " data_channel_is_world          0               0.0              \n",
       " kw_min_min                     0               0.0              "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = r'C:\\Users\\pmspr\\Documents\\HS\\MS\\Sem 3\\EECS 731\\Project\\Repos\\News Popularity\\Git\\EECS-731-Project-7\\Data'\n",
    "filename = \"OnlineNewsPopularity.csv\"\n",
    "data = loadData(path,filename)\n",
    "\n",
    "#Check the missing values\n",
    "misVal, mis_val_table_ren_columns = missingValues(data)\n",
    "display(mis_val_table_ren_columns.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>timedelta</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>354.530471</td>\n",
       "      <td>214.163767</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>542.000000</td>\n",
       "      <td>731.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_tokens_title</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>10.398749</td>\n",
       "      <td>2.114037</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_tokens_content</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>546.514731</td>\n",
       "      <td>471.107508</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>246.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>716.000000</td>\n",
       "      <td>8474.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.548216</td>\n",
       "      <td>3.520708</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.470870</td>\n",
       "      <td>0.539226</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>701.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.996469</td>\n",
       "      <td>5.231231</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1042.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.689175</td>\n",
       "      <td>3.264816</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.625739</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.754630</td>\n",
       "      <td>650.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_hrefs</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>10.883690</td>\n",
       "      <td>11.332017</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>304.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>3.293638</td>\n",
       "      <td>3.855141</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>116.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_imgs</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>4.544143</td>\n",
       "      <td>8.309434</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>128.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_videos</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>1.249874</td>\n",
       "      <td>4.107855</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>91.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_token_length</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>4.548239</td>\n",
       "      <td>0.844406</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.478404</td>\n",
       "      <td>4.664082</td>\n",
       "      <td>4.854839</td>\n",
       "      <td>8.041534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_keywords</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>7.223767</td>\n",
       "      <td>1.909130</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_channel_is_lifestyle</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.052946</td>\n",
       "      <td>0.223929</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_channel_is_entertainment</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.178009</td>\n",
       "      <td>0.382525</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_channel_is_bus</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.157855</td>\n",
       "      <td>0.364610</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_channel_is_socmed</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.058597</td>\n",
       "      <td>0.234871</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_channel_is_tech</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.185299</td>\n",
       "      <td>0.388545</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_channel_is_world</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.212567</td>\n",
       "      <td>0.409129</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_min_min</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>26.106801</td>\n",
       "      <td>69.633215</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>377.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_max_min</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>1153.951682</td>\n",
       "      <td>3857.990877</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>445.000000</td>\n",
       "      <td>660.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>298400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_avg_min</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>312.366967</td>\n",
       "      <td>620.783887</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>141.750000</td>\n",
       "      <td>235.500000</td>\n",
       "      <td>357.000000</td>\n",
       "      <td>42827.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_min_max</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>13612.354102</td>\n",
       "      <td>57986.029357</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>7900.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_max_max</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>752324.066694</td>\n",
       "      <td>214502.129573</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>843300.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_avg_max</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>259281.938083</td>\n",
       "      <td>135102.247285</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>172846.875000</td>\n",
       "      <td>244572.222223</td>\n",
       "      <td>330980.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_min_avg</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>1117.146610</td>\n",
       "      <td>1137.456951</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1023.635611</td>\n",
       "      <td>2056.781032</td>\n",
       "      <td>3613.039820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_max_avg</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>5657.211151</td>\n",
       "      <td>6098.871957</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3562.101631</td>\n",
       "      <td>4355.688836</td>\n",
       "      <td>6019.953968</td>\n",
       "      <td>298400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_avg_avg</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>3135.858639</td>\n",
       "      <td>1318.150397</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2382.448566</td>\n",
       "      <td>2870.074878</td>\n",
       "      <td>3600.229564</td>\n",
       "      <td>43567.659946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self_reference_min_shares</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>3998.755396</td>\n",
       "      <td>19738.670516</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>639.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>2600.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self_reference_max_shares</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>10329.212662</td>\n",
       "      <td>41027.576613</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1100.000000</td>\n",
       "      <td>2800.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self_reference_avg_sharess</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>6401.697580</td>\n",
       "      <td>24211.332231</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>981.187500</td>\n",
       "      <td>2200.000000</td>\n",
       "      <td>5200.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_is_monday</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.168020</td>\n",
       "      <td>0.373889</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_is_tuesday</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.186409</td>\n",
       "      <td>0.389441</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_is_wednesday</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.187544</td>\n",
       "      <td>0.390353</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_is_thursday</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.183306</td>\n",
       "      <td>0.386922</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_is_friday</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.143805</td>\n",
       "      <td>0.350896</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_is_saturday</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.061876</td>\n",
       "      <td>0.240933</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_is_sunday</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.069039</td>\n",
       "      <td>0.253524</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_weekend</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.130915</td>\n",
       "      <td>0.337312</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA_00</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.184599</td>\n",
       "      <td>0.262975</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.025051</td>\n",
       "      <td>0.033387</td>\n",
       "      <td>0.240958</td>\n",
       "      <td>0.926994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA_01</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.141256</td>\n",
       "      <td>0.219707</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.025012</td>\n",
       "      <td>0.033345</td>\n",
       "      <td>0.150831</td>\n",
       "      <td>0.925947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA_02</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.216321</td>\n",
       "      <td>0.282145</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.040004</td>\n",
       "      <td>0.334218</td>\n",
       "      <td>0.919999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA_03</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.223770</td>\n",
       "      <td>0.295191</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.040001</td>\n",
       "      <td>0.375763</td>\n",
       "      <td>0.926534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA_04</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.234029</td>\n",
       "      <td>0.289183</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.028574</td>\n",
       "      <td>0.040727</td>\n",
       "      <td>0.399986</td>\n",
       "      <td>0.927191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_subjectivity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.443370</td>\n",
       "      <td>0.116685</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.396167</td>\n",
       "      <td>0.453457</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_sentiment_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.119309</td>\n",
       "      <td>0.096931</td>\n",
       "      <td>-0.39375</td>\n",
       "      <td>0.057757</td>\n",
       "      <td>0.119117</td>\n",
       "      <td>0.177832</td>\n",
       "      <td>0.727841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_rate_positive_words</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.039625</td>\n",
       "      <td>0.017429</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.028384</td>\n",
       "      <td>0.039023</td>\n",
       "      <td>0.050279</td>\n",
       "      <td>0.155488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_rate_negative_words</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.016612</td>\n",
       "      <td>0.010828</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.009615</td>\n",
       "      <td>0.015337</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.184932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rate_positive_words</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.682150</td>\n",
       "      <td>0.190206</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rate_negative_words</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.287934</td>\n",
       "      <td>0.156156</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.353825</td>\n",
       "      <td>0.104542</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.306244</td>\n",
       "      <td>0.358755</td>\n",
       "      <td>0.411428</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.095446</td>\n",
       "      <td>0.071315</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.756728</td>\n",
       "      <td>0.247786</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>-0.259524</td>\n",
       "      <td>0.127726</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-0.328383</td>\n",
       "      <td>-0.253333</td>\n",
       "      <td>-0.186905</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>-0.521944</td>\n",
       "      <td>0.290290</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>-0.107500</td>\n",
       "      <td>0.095373</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_subjectivity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.324247</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.071425</td>\n",
       "      <td>0.265450</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.341843</td>\n",
       "      <td>0.188791</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.156064</td>\n",
       "      <td>0.226294</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shares</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>3395.380184</td>\n",
       "      <td>11626.950749</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>946.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>2800.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  count           mean            std  \\\n",
       " timedelta                      39644.0  354.530471     214.163767      \n",
       " n_tokens_title                 39644.0  10.398749      2.114037        \n",
       " n_tokens_content               39644.0  546.514731     471.107508      \n",
       " n_unique_tokens                39644.0  0.548216       3.520708        \n",
       " n_non_stop_words               39644.0  0.996469       5.231231        \n",
       " n_non_stop_unique_tokens       39644.0  0.689175       3.264816        \n",
       " num_hrefs                      39644.0  10.883690      11.332017       \n",
       " num_self_hrefs                 39644.0  3.293638       3.855141        \n",
       " num_imgs                       39644.0  4.544143       8.309434        \n",
       " num_videos                     39644.0  1.249874       4.107855        \n",
       " average_token_length           39644.0  4.548239       0.844406        \n",
       " num_keywords                   39644.0  7.223767       1.909130        \n",
       " data_channel_is_lifestyle      39644.0  0.052946       0.223929        \n",
       " data_channel_is_entertainment  39644.0  0.178009       0.382525        \n",
       " data_channel_is_bus            39644.0  0.157855       0.364610        \n",
       " data_channel_is_socmed         39644.0  0.058597       0.234871        \n",
       " data_channel_is_tech           39644.0  0.185299       0.388545        \n",
       " data_channel_is_world          39644.0  0.212567       0.409129        \n",
       " kw_min_min                     39644.0  26.106801      69.633215       \n",
       " kw_max_min                     39644.0  1153.951682    3857.990877     \n",
       " kw_avg_min                     39644.0  312.366967     620.783887      \n",
       " kw_min_max                     39644.0  13612.354102   57986.029357    \n",
       " kw_max_max                     39644.0  752324.066694  214502.129573   \n",
       " kw_avg_max                     39644.0  259281.938083  135102.247285   \n",
       " kw_min_avg                     39644.0  1117.146610    1137.456951     \n",
       " kw_max_avg                     39644.0  5657.211151    6098.871957     \n",
       " kw_avg_avg                     39644.0  3135.858639    1318.150397     \n",
       " self_reference_min_shares      39644.0  3998.755396    19738.670516    \n",
       " self_reference_max_shares      39644.0  10329.212662   41027.576613    \n",
       " self_reference_avg_sharess     39644.0  6401.697580    24211.332231    \n",
       " weekday_is_monday              39644.0  0.168020       0.373889        \n",
       " weekday_is_tuesday             39644.0  0.186409       0.389441        \n",
       " weekday_is_wednesday           39644.0  0.187544       0.390353        \n",
       " weekday_is_thursday            39644.0  0.183306       0.386922        \n",
       " weekday_is_friday              39644.0  0.143805       0.350896        \n",
       " weekday_is_saturday            39644.0  0.061876       0.240933        \n",
       " weekday_is_sunday              39644.0  0.069039       0.253524        \n",
       " is_weekend                     39644.0  0.130915       0.337312        \n",
       " LDA_00                         39644.0  0.184599       0.262975        \n",
       " LDA_01                         39644.0  0.141256       0.219707        \n",
       " LDA_02                         39644.0  0.216321       0.282145        \n",
       " LDA_03                         39644.0  0.223770       0.295191        \n",
       " LDA_04                         39644.0  0.234029       0.289183        \n",
       " global_subjectivity            39644.0  0.443370       0.116685        \n",
       " global_sentiment_polarity      39644.0  0.119309       0.096931        \n",
       " global_rate_positive_words     39644.0  0.039625       0.017429        \n",
       " global_rate_negative_words     39644.0  0.016612       0.010828        \n",
       " rate_positive_words            39644.0  0.682150       0.190206        \n",
       " rate_negative_words            39644.0  0.287934       0.156156        \n",
       " avg_positive_polarity          39644.0  0.353825       0.104542        \n",
       " min_positive_polarity          39644.0  0.095446       0.071315        \n",
       " max_positive_polarity          39644.0  0.756728       0.247786        \n",
       " avg_negative_polarity          39644.0 -0.259524       0.127726        \n",
       " min_negative_polarity          39644.0 -0.521944       0.290290        \n",
       " max_negative_polarity          39644.0 -0.107500       0.095373        \n",
       " title_subjectivity             39644.0  0.282353       0.324247        \n",
       " title_sentiment_polarity       39644.0  0.071425       0.265450        \n",
       " abs_title_subjectivity         39644.0  0.341843       0.188791        \n",
       " abs_title_sentiment_polarity   39644.0  0.156064       0.226294        \n",
       " shares                         39644.0  3395.380184    11626.950749    \n",
       "\n",
       "                                    min            25%            50%  \\\n",
       " timedelta                      8.00000  164.000000     339.000000      \n",
       " n_tokens_title                 2.00000  9.000000       10.000000       \n",
       " n_tokens_content               0.00000  246.000000     409.000000      \n",
       " n_unique_tokens                0.00000  0.470870       0.539226        \n",
       " n_non_stop_words               0.00000  1.000000       1.000000        \n",
       " n_non_stop_unique_tokens       0.00000  0.625739       0.690476        \n",
       " num_hrefs                      0.00000  4.000000       8.000000        \n",
       " num_self_hrefs                 0.00000  1.000000       3.000000        \n",
       " num_imgs                       0.00000  1.000000       1.000000        \n",
       " num_videos                     0.00000  0.000000       0.000000        \n",
       " average_token_length           0.00000  4.478404       4.664082        \n",
       " num_keywords                   1.00000  6.000000       7.000000        \n",
       " data_channel_is_lifestyle      0.00000  0.000000       0.000000        \n",
       " data_channel_is_entertainment  0.00000  0.000000       0.000000        \n",
       " data_channel_is_bus            0.00000  0.000000       0.000000        \n",
       " data_channel_is_socmed         0.00000  0.000000       0.000000        \n",
       " data_channel_is_tech           0.00000  0.000000       0.000000        \n",
       " data_channel_is_world          0.00000  0.000000       0.000000        \n",
       " kw_min_min                    -1.00000 -1.000000      -1.000000        \n",
       " kw_max_min                     0.00000  445.000000     660.000000      \n",
       " kw_avg_min                    -1.00000  141.750000     235.500000      \n",
       " kw_min_max                     0.00000  0.000000       1400.000000     \n",
       " kw_max_max                     0.00000  843300.000000  843300.000000   \n",
       " kw_avg_max                     0.00000  172846.875000  244572.222223   \n",
       " kw_min_avg                    -1.00000  0.000000       1023.635611     \n",
       " kw_max_avg                     0.00000  3562.101631    4355.688836     \n",
       " kw_avg_avg                     0.00000  2382.448566    2870.074878     \n",
       " self_reference_min_shares      0.00000  639.000000     1200.000000     \n",
       " self_reference_max_shares      0.00000  1100.000000    2800.000000     \n",
       " self_reference_avg_sharess     0.00000  981.187500     2200.000000     \n",
       " weekday_is_monday              0.00000  0.000000       0.000000        \n",
       " weekday_is_tuesday             0.00000  0.000000       0.000000        \n",
       " weekday_is_wednesday           0.00000  0.000000       0.000000        \n",
       " weekday_is_thursday            0.00000  0.000000       0.000000        \n",
       " weekday_is_friday              0.00000  0.000000       0.000000        \n",
       " weekday_is_saturday            0.00000  0.000000       0.000000        \n",
       " weekday_is_sunday              0.00000  0.000000       0.000000        \n",
       " is_weekend                     0.00000  0.000000       0.000000        \n",
       " LDA_00                         0.00000  0.025051       0.033387        \n",
       " LDA_01                         0.00000  0.025012       0.033345        \n",
       " LDA_02                         0.00000  0.028571       0.040004        \n",
       " LDA_03                         0.00000  0.028571       0.040001        \n",
       " LDA_04                         0.00000  0.028574       0.040727        \n",
       " global_subjectivity            0.00000  0.396167       0.453457        \n",
       " global_sentiment_polarity     -0.39375  0.057757       0.119117        \n",
       " global_rate_positive_words     0.00000  0.028384       0.039023        \n",
       " global_rate_negative_words     0.00000  0.009615       0.015337        \n",
       " rate_positive_words            0.00000  0.600000       0.710526        \n",
       " rate_negative_words            0.00000  0.185185       0.280000        \n",
       " avg_positive_polarity          0.00000  0.306244       0.358755        \n",
       " min_positive_polarity          0.00000  0.050000       0.100000        \n",
       " max_positive_polarity          0.00000  0.600000       0.800000        \n",
       " avg_negative_polarity         -1.00000 -0.328383      -0.253333        \n",
       " min_negative_polarity         -1.00000 -0.700000      -0.500000        \n",
       " max_negative_polarity         -1.00000 -0.125000      -0.100000        \n",
       " title_subjectivity             0.00000  0.000000       0.150000        \n",
       " title_sentiment_polarity      -1.00000  0.000000       0.000000        \n",
       " abs_title_subjectivity         0.00000  0.166667       0.500000        \n",
       " abs_title_sentiment_polarity   0.00000  0.000000       0.000000        \n",
       " shares                         1.00000  946.000000     1400.000000     \n",
       "\n",
       "                                          75%            max  \n",
       " timedelta                      542.000000     731.000000     \n",
       " n_tokens_title                 12.000000      23.000000      \n",
       " n_tokens_content               716.000000     8474.000000    \n",
       " n_unique_tokens                0.608696       701.000000     \n",
       " n_non_stop_words               1.000000       1042.000000    \n",
       " n_non_stop_unique_tokens       0.754630       650.000000     \n",
       " num_hrefs                      14.000000      304.000000     \n",
       " num_self_hrefs                 4.000000       116.000000     \n",
       " num_imgs                       4.000000       128.000000     \n",
       " num_videos                     1.000000       91.000000      \n",
       " average_token_length           4.854839       8.041534       \n",
       " num_keywords                   9.000000       10.000000      \n",
       " data_channel_is_lifestyle      0.000000       1.000000       \n",
       " data_channel_is_entertainment  0.000000       1.000000       \n",
       " data_channel_is_bus            0.000000       1.000000       \n",
       " data_channel_is_socmed         0.000000       1.000000       \n",
       " data_channel_is_tech           0.000000       1.000000       \n",
       " data_channel_is_world          0.000000       1.000000       \n",
       " kw_min_min                     4.000000       377.000000     \n",
       " kw_max_min                     1000.000000    298400.000000  \n",
       " kw_avg_min                     357.000000     42827.857143   \n",
       " kw_min_max                     7900.000000    843300.000000  \n",
       " kw_max_max                     843300.000000  843300.000000  \n",
       " kw_avg_max                     330980.000000  843300.000000  \n",
       " kw_min_avg                     2056.781032    3613.039820    \n",
       " kw_max_avg                     6019.953968    298400.000000  \n",
       " kw_avg_avg                     3600.229564    43567.659946   \n",
       " self_reference_min_shares      2600.000000    843300.000000  \n",
       " self_reference_max_shares      8000.000000    843300.000000  \n",
       " self_reference_avg_sharess     5200.000000    843300.000000  \n",
       " weekday_is_monday              0.000000       1.000000       \n",
       " weekday_is_tuesday             0.000000       1.000000       \n",
       " weekday_is_wednesday           0.000000       1.000000       \n",
       " weekday_is_thursday            0.000000       1.000000       \n",
       " weekday_is_friday              0.000000       1.000000       \n",
       " weekday_is_saturday            0.000000       1.000000       \n",
       " weekday_is_sunday              0.000000       1.000000       \n",
       " is_weekend                     0.000000       1.000000       \n",
       " LDA_00                         0.240958       0.926994       \n",
       " LDA_01                         0.150831       0.925947       \n",
       " LDA_02                         0.334218       0.919999       \n",
       " LDA_03                         0.375763       0.926534       \n",
       " LDA_04                         0.399986       0.927191       \n",
       " global_subjectivity            0.508333       1.000000       \n",
       " global_sentiment_polarity      0.177832       0.727841       \n",
       " global_rate_positive_words     0.050279       0.155488       \n",
       " global_rate_negative_words     0.021739       0.184932       \n",
       " rate_positive_words            0.800000       1.000000       \n",
       " rate_negative_words            0.384615       1.000000       \n",
       " avg_positive_polarity          0.411428       1.000000       \n",
       " min_positive_polarity          0.100000       1.000000       \n",
       " max_positive_polarity          1.000000       1.000000       \n",
       " avg_negative_polarity         -0.186905       0.000000       \n",
       " min_negative_polarity         -0.300000       0.000000       \n",
       " max_negative_polarity         -0.050000       0.000000       \n",
       " title_subjectivity             0.500000       1.000000       \n",
       " title_sentiment_polarity       0.150000       1.000000       \n",
       " abs_title_subjectivity         0.500000       0.500000       \n",
       " abs_title_sentiment_polarity   0.250000       1.000000       \n",
       " shares                         2800.000000    843300.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "des = data.describe().transpose()\n",
    "display(des)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------\n",
      "Total number of records: 39644\n",
      "Total number of features: 60\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Remove rows with missing target values\n",
    "col = ['url']\n",
    "data = data.drop(columns=col, axis=1)\n",
    "\n",
    "exploreData(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore and Tansform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\pandas\\core\\indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>timedelta</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.479295</td>\n",
       "      <td>0.296215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.215768</td>\n",
       "      <td>0.457815</td>\n",
       "      <td>0.738589</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_tokens_title</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.399940</td>\n",
       "      <td>0.100668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_tokens_content</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.064493</td>\n",
       "      <td>0.055594</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029030</td>\n",
       "      <td>0.048265</td>\n",
       "      <td>0.084494</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>0.005022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.000769</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.000956</td>\n",
       "      <td>0.005020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000960</td>\n",
       "      <td>0.000960</td>\n",
       "      <td>0.000960</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.001060</td>\n",
       "      <td>0.005023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000963</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.001161</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_hrefs</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.035802</td>\n",
       "      <td>0.037276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.046053</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.028393</td>\n",
       "      <td>0.033234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.025862</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_imgs</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.035501</td>\n",
       "      <td>0.064917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_videos</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.013735</td>\n",
       "      <td>0.045141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_token_length</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.565594</td>\n",
       "      <td>0.105006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.556909</td>\n",
       "      <td>0.579999</td>\n",
       "      <td>0.603721</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_keywords</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.691530</td>\n",
       "      <td>0.212126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_channel_is_lifestyle</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.052946</td>\n",
       "      <td>0.223929</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_channel_is_entertainment</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.178009</td>\n",
       "      <td>0.382525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_channel_is_bus</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.157855</td>\n",
       "      <td>0.364610</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_channel_is_socmed</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.058597</td>\n",
       "      <td>0.234871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_channel_is_tech</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.185299</td>\n",
       "      <td>0.388545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_channel_is_world</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.212567</td>\n",
       "      <td>0.409129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_min_min</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.071711</td>\n",
       "      <td>0.184215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013228</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_max_min</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>0.012929</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001491</td>\n",
       "      <td>0.002212</td>\n",
       "      <td>0.003351</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_avg_min</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.007317</td>\n",
       "      <td>0.014495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.005522</td>\n",
       "      <td>0.008359</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_min_max</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.016142</td>\n",
       "      <td>0.068761</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001660</td>\n",
       "      <td>0.009368</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_max_max</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.892119</td>\n",
       "      <td>0.254360</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_avg_max</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.307461</td>\n",
       "      <td>0.160207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.204965</td>\n",
       "      <td>0.290018</td>\n",
       "      <td>0.392482</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_min_avg</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.309390</td>\n",
       "      <td>0.314733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.283515</td>\n",
       "      <td>0.569385</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_max_avg</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.018958</td>\n",
       "      <td>0.020439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011937</td>\n",
       "      <td>0.014597</td>\n",
       "      <td>0.020174</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_avg_avg</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.071977</td>\n",
       "      <td>0.030255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054684</td>\n",
       "      <td>0.065876</td>\n",
       "      <td>0.082635</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self_reference_min_shares</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.004742</td>\n",
       "      <td>0.023406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>0.003083</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self_reference_max_shares</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.012249</td>\n",
       "      <td>0.048651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>0.003320</td>\n",
       "      <td>0.009487</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self_reference_avg_sharess</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.007591</td>\n",
       "      <td>0.028710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.002609</td>\n",
       "      <td>0.006166</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_is_monday</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.168020</td>\n",
       "      <td>0.373889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_is_tuesday</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.186409</td>\n",
       "      <td>0.389441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_is_wednesday</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.187544</td>\n",
       "      <td>0.390353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_is_thursday</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.183306</td>\n",
       "      <td>0.386922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_is_friday</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.143805</td>\n",
       "      <td>0.350896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_is_saturday</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.061876</td>\n",
       "      <td>0.240933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_is_sunday</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.069039</td>\n",
       "      <td>0.253524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_weekend</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.130915</td>\n",
       "      <td>0.337312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA_00</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.184599</td>\n",
       "      <td>0.262975</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025051</td>\n",
       "      <td>0.033387</td>\n",
       "      <td>0.240958</td>\n",
       "      <td>0.926994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA_01</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.141256</td>\n",
       "      <td>0.219707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025012</td>\n",
       "      <td>0.033345</td>\n",
       "      <td>0.150831</td>\n",
       "      <td>0.925947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA_02</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.216321</td>\n",
       "      <td>0.282145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.040004</td>\n",
       "      <td>0.334218</td>\n",
       "      <td>0.919999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA_03</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.223770</td>\n",
       "      <td>0.295191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.040001</td>\n",
       "      <td>0.375763</td>\n",
       "      <td>0.926534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA_04</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.234029</td>\n",
       "      <td>0.289183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028574</td>\n",
       "      <td>0.040727</td>\n",
       "      <td>0.399986</td>\n",
       "      <td>0.927191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_subjectivity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.443370</td>\n",
       "      <td>0.116685</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.396167</td>\n",
       "      <td>0.453457</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_sentiment_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.513059</td>\n",
       "      <td>0.096931</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.451507</td>\n",
       "      <td>0.512867</td>\n",
       "      <td>0.571582</td>\n",
       "      <td>1.121591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_rate_positive_words</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.039625</td>\n",
       "      <td>0.017429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028384</td>\n",
       "      <td>0.039023</td>\n",
       "      <td>0.050279</td>\n",
       "      <td>0.155488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_rate_negative_words</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.016612</td>\n",
       "      <td>0.010828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009615</td>\n",
       "      <td>0.015337</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.184932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rate_positive_words</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.682150</td>\n",
       "      <td>0.190206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rate_negative_words</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.287934</td>\n",
       "      <td>0.156156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.353825</td>\n",
       "      <td>0.104542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306244</td>\n",
       "      <td>0.358755</td>\n",
       "      <td>0.411428</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.095446</td>\n",
       "      <td>0.071315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.756728</td>\n",
       "      <td>0.247786</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.740476</td>\n",
       "      <td>0.127726</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.671617</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>0.813095</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.478056</td>\n",
       "      <td>0.290290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.095373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_subjectivity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.324247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>1.071425</td>\n",
       "      <td>0.265450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.150000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.341843</td>\n",
       "      <td>0.188791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <td>39644.0</td>\n",
       "      <td>0.156064</td>\n",
       "      <td>0.226294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  count      mean       std  min       25%  \\\n",
       " timedelta                      39644.0  0.479295  0.296215  0.0  0.215768   \n",
       " n_tokens_title                 39644.0  0.399940  0.100668  0.0  0.333333   \n",
       " n_tokens_content               39644.0  0.064493  0.055594  0.0  0.029030   \n",
       " n_unique_tokens                39644.0  0.000782  0.005022  0.0  0.000672   \n",
       " n_non_stop_words               39644.0  0.000956  0.005020  0.0  0.000960   \n",
       " n_non_stop_unique_tokens       39644.0  0.001060  0.005023  0.0  0.000963   \n",
       " num_hrefs                      39644.0  0.035802  0.037276  0.0  0.013158   \n",
       " num_self_hrefs                 39644.0  0.028393  0.033234  0.0  0.008621   \n",
       " num_imgs                       39644.0  0.035501  0.064917  0.0  0.007812   \n",
       " num_videos                     39644.0  0.013735  0.045141  0.0  0.000000   \n",
       " average_token_length           39644.0  0.565594  0.105006  0.0  0.556909   \n",
       " num_keywords                   39644.0  0.691530  0.212126  0.0  0.555556   \n",
       " data_channel_is_lifestyle      39644.0  0.052946  0.223929  0.0  0.000000   \n",
       " data_channel_is_entertainment  39644.0  0.178009  0.382525  0.0  0.000000   \n",
       " data_channel_is_bus            39644.0  0.157855  0.364610  0.0  0.000000   \n",
       " data_channel_is_socmed         39644.0  0.058597  0.234871  0.0  0.000000   \n",
       " data_channel_is_tech           39644.0  0.185299  0.388545  0.0  0.000000   \n",
       " data_channel_is_world          39644.0  0.212567  0.409129  0.0  0.000000   \n",
       " kw_min_min                     39644.0  0.071711  0.184215  0.0  0.000000   \n",
       " kw_max_min                     39644.0  0.003867  0.012929  0.0  0.001491   \n",
       " kw_avg_min                     39644.0  0.007317  0.014495  0.0  0.003333   \n",
       " kw_min_max                     39644.0  0.016142  0.068761  0.0  0.000000   \n",
       " kw_max_max                     39644.0  0.892119  0.254360  0.0  1.000000   \n",
       " kw_avg_max                     39644.0  0.307461  0.160207  0.0  0.204965   \n",
       " kw_min_avg                     39644.0  0.309390  0.314733  0.0  0.000277   \n",
       " kw_max_avg                     39644.0  0.018958  0.020439  0.0  0.011937   \n",
       " kw_avg_avg                     39644.0  0.071977  0.030255  0.0  0.054684   \n",
       " self_reference_min_shares      39644.0  0.004742  0.023406  0.0  0.000758   \n",
       " self_reference_max_shares      39644.0  0.012249  0.048651  0.0  0.001304   \n",
       " self_reference_avg_sharess     39644.0  0.007591  0.028710  0.0  0.001164   \n",
       " weekday_is_monday              39644.0  0.168020  0.373889  0.0  0.000000   \n",
       " weekday_is_tuesday             39644.0  0.186409  0.389441  0.0  0.000000   \n",
       " weekday_is_wednesday           39644.0  0.187544  0.390353  0.0  0.000000   \n",
       " weekday_is_thursday            39644.0  0.183306  0.386922  0.0  0.000000   \n",
       " weekday_is_friday              39644.0  0.143805  0.350896  0.0  0.000000   \n",
       " weekday_is_saturday            39644.0  0.061876  0.240933  0.0  0.000000   \n",
       " weekday_is_sunday              39644.0  0.069039  0.253524  0.0  0.000000   \n",
       " is_weekend                     39644.0  0.130915  0.337312  0.0  0.000000   \n",
       " LDA_00                         39644.0  0.184599  0.262975  0.0  0.025051   \n",
       " LDA_01                         39644.0  0.141256  0.219707  0.0  0.025012   \n",
       " LDA_02                         39644.0  0.216321  0.282145  0.0  0.028571   \n",
       " LDA_03                         39644.0  0.223770  0.295191  0.0  0.028571   \n",
       " LDA_04                         39644.0  0.234029  0.289183  0.0  0.028574   \n",
       " global_subjectivity            39644.0  0.443370  0.116685  0.0  0.396167   \n",
       " global_sentiment_polarity      39644.0  0.513059  0.096931  0.0  0.451507   \n",
       " global_rate_positive_words     39644.0  0.039625  0.017429  0.0  0.028384   \n",
       " global_rate_negative_words     39644.0  0.016612  0.010828  0.0  0.009615   \n",
       " rate_positive_words            39644.0  0.682150  0.190206  0.0  0.600000   \n",
       " rate_negative_words            39644.0  0.287934  0.156156  0.0  0.185185   \n",
       " avg_positive_polarity          39644.0  0.353825  0.104542  0.0  0.306244   \n",
       " min_positive_polarity          39644.0  0.095446  0.071315  0.0  0.050000   \n",
       " max_positive_polarity          39644.0  0.756728  0.247786  0.0  0.600000   \n",
       " avg_negative_polarity          39644.0  0.740476  0.127726  0.0  0.671617   \n",
       " min_negative_polarity          39644.0  0.478056  0.290290  0.0  0.300000   \n",
       " max_negative_polarity          39644.0  0.892500  0.095373  0.0  0.875000   \n",
       " title_subjectivity             39644.0  0.282353  0.324247  0.0  0.000000   \n",
       " title_sentiment_polarity       39644.0  1.071425  0.265450  0.0  1.000000   \n",
       " abs_title_subjectivity         39644.0  0.341843  0.188791  0.0  0.166667   \n",
       " abs_title_sentiment_polarity   39644.0  0.156064  0.226294  0.0  0.000000   \n",
       "\n",
       "                                     50%       75%       max  \n",
       " timedelta                      0.457815  0.738589  1.000000  \n",
       " n_tokens_title                 0.380952  0.476190  1.000000  \n",
       " n_tokens_content               0.048265  0.084494  1.000000  \n",
       " n_unique_tokens                0.000769  0.000868  1.000000  \n",
       " n_non_stop_words               0.000960  0.000960  1.000000  \n",
       " n_non_stop_unique_tokens       0.001062  0.001161  1.000000  \n",
       " num_hrefs                      0.026316  0.046053  1.000000  \n",
       " num_self_hrefs                 0.025862  0.034483  1.000000  \n",
       " num_imgs                       0.007812  0.031250  1.000000  \n",
       " num_videos                     0.000000  0.010989  1.000000  \n",
       " average_token_length           0.579999  0.603721  1.000000  \n",
       " num_keywords                   0.666667  0.888889  1.000000  \n",
       " data_channel_is_lifestyle      0.000000  0.000000  1.000000  \n",
       " data_channel_is_entertainment  0.000000  0.000000  1.000000  \n",
       " data_channel_is_bus            0.000000  0.000000  1.000000  \n",
       " data_channel_is_socmed         0.000000  0.000000  1.000000  \n",
       " data_channel_is_tech           0.000000  0.000000  1.000000  \n",
       " data_channel_is_world          0.000000  0.000000  1.000000  \n",
       " kw_min_min                     0.000000  0.013228  1.000000  \n",
       " kw_max_min                     0.002212  0.003351  1.000000  \n",
       " kw_avg_min                     0.005522  0.008359  1.000000  \n",
       " kw_min_max                     0.001660  0.009368  1.000000  \n",
       " kw_max_max                     1.000000  1.000000  1.000000  \n",
       " kw_avg_max                     0.290018  0.392482  1.000000  \n",
       " kw_min_avg                     0.283515  0.569385  1.000000  \n",
       " kw_max_avg                     0.014597  0.020174  1.000000  \n",
       " kw_avg_avg                     0.065876  0.082635  1.000000  \n",
       " self_reference_min_shares      0.001423  0.003083  1.000000  \n",
       " self_reference_max_shares      0.003320  0.009487  1.000000  \n",
       " self_reference_avg_sharess     0.002609  0.006166  1.000000  \n",
       " weekday_is_monday              0.000000  0.000000  1.000000  \n",
       " weekday_is_tuesday             0.000000  0.000000  1.000000  \n",
       " weekday_is_wednesday           0.000000  0.000000  1.000000  \n",
       " weekday_is_thursday            0.000000  0.000000  1.000000  \n",
       " weekday_is_friday              0.000000  0.000000  1.000000  \n",
       " weekday_is_saturday            0.000000  0.000000  1.000000  \n",
       " weekday_is_sunday              0.000000  0.000000  1.000000  \n",
       " is_weekend                     0.000000  0.000000  1.000000  \n",
       " LDA_00                         0.033387  0.240958  0.926994  \n",
       " LDA_01                         0.033345  0.150831  0.925947  \n",
       " LDA_02                         0.040004  0.334218  0.919999  \n",
       " LDA_03                         0.040001  0.375763  0.926534  \n",
       " LDA_04                         0.040727  0.399986  0.927191  \n",
       " global_subjectivity            0.453457  0.508333  1.000000  \n",
       " global_sentiment_polarity      0.512867  0.571582  1.121591  \n",
       " global_rate_positive_words     0.039023  0.050279  0.155488  \n",
       " global_rate_negative_words     0.015337  0.021739  0.184932  \n",
       " rate_positive_words            0.710526  0.800000  1.000000  \n",
       " rate_negative_words            0.280000  0.384615  1.000000  \n",
       " avg_positive_polarity          0.358755  0.411428  1.000000  \n",
       " min_positive_polarity          0.100000  0.100000  1.000000  \n",
       " max_positive_polarity          0.800000  1.000000  1.000000  \n",
       " avg_negative_polarity          0.746667  0.813095  1.000000  \n",
       " min_negative_polarity          0.500000  0.700000  1.000000  \n",
       " max_negative_polarity          0.900000  0.950000  1.000000  \n",
       " title_subjectivity             0.150000  0.500000  1.000000  \n",
       " title_sentiment_polarity       1.000000  1.150000  2.000000  \n",
       " abs_title_subjectivity         0.500000  0.500000  0.500000  \n",
       " abs_title_sentiment_polarity   0.000000  0.250000  1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_raw = data\n",
    "features, target = transformData(data_raw)\n",
    "display(features.describe().transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data between training and test sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features training set has 27750 samples.\n",
      "Features testing set has 11894 samples.\n",
      "Target training set has 27750 samples.\n",
      "Target testing set has 11894 samples.\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Split the data 70% training and 30% test\n",
    "X_train, X_test, y_train, y_test = splitData(features,target,0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement the Multinomial bayesian classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Times for Training, Prediction: 0.07551, 0.00480\n",
      "Accuracy for Training, Test sets: 0.62930, 0.63032\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Multinomial naive bayesian classifer\n",
    "results,learner = multinomialnb(X_train, X_test, y_train, y_test)\n",
    "\n",
    "print (\"Times for Training, Prediction: %.5f, %.5f\" %(results['train_time'], results['pred_time']))    \n",
    "print (\"Accuracy for Training, Test sets: %.5f, %.5f\" %(results['acc_train'], results['acc_test']))     \n",
    "print (\"-----------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Times for Training, Prediction: 245.66576, 67.42515\n",
      "Accuracy for Training, Test sets: 0.61542, 0.61308\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Implement Support Vector Machine Classifier\n",
    "results,learner = svmClassifier(X_train, X_test, y_train, y_test)\n",
    "\n",
    "print (\"Times for Training, Prediction: %.5f, %.5f\" %(results['train_time'], results['pred_time']))    \n",
    "print (\"Accuracy for Training, Test sets: %.5f, %.5f\" %(results['acc_train'], results['acc_test']))     \n",
    "print (\"-----------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement Random forest tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n_non_stop_words</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>weekday_is_monday</td>\n",
       "      <td>0.000394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>weekday_is_tuesday</td>\n",
       "      <td>0.000398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>weekday_is_wednesday</td>\n",
       "      <td>0.000411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>weekday_is_friday</td>\n",
       "      <td>0.000511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>weekday_is_thursday</td>\n",
       "      <td>0.000614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>data_channel_is_lifestyle</td>\n",
       "      <td>0.000911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>kw_min_min</td>\n",
       "      <td>0.002676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>min_negative_polarity</td>\n",
       "      <td>0.002785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>max_positive_polarity</td>\n",
       "      <td>0.003009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>data_channel_is_bus</td>\n",
       "      <td>0.003217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>abs_title_subjectivity</td>\n",
       "      <td>0.003236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n_tokens_title</td>\n",
       "      <td>0.003290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>abs_title_sentiment_polarity</td>\n",
       "      <td>0.004017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>num_videos</td>\n",
       "      <td>0.004442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>num_keywords</td>\n",
       "      <td>0.004463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>title_sentiment_polarity</td>\n",
       "      <td>0.004822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>title_subjectivity</td>\n",
       "      <td>0.005407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>num_self_hrefs</td>\n",
       "      <td>0.005438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>max_negative_polarity</td>\n",
       "      <td>0.005970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>weekday_is_sunday</td>\n",
       "      <td>0.006597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>rate_positive_words</td>\n",
       "      <td>0.006879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>min_positive_polarity</td>\n",
       "      <td>0.007158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>kw_max_max</td>\n",
       "      <td>0.007160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>global_rate_negative_words</td>\n",
       "      <td>0.007863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>num_imgs</td>\n",
       "      <td>0.008034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>LDA_03</td>\n",
       "      <td>0.009817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>kw_max_min</td>\n",
       "      <td>0.009992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>global_rate_positive_words</td>\n",
       "      <td>0.010077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>avg_negative_polarity</td>\n",
       "      <td>0.010291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>avg_positive_polarity</td>\n",
       "      <td>0.011230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>average_token_length</td>\n",
       "      <td>0.011330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>data_channel_is_tech</td>\n",
       "      <td>0.012302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>rate_negative_words</td>\n",
       "      <td>0.012495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>global_sentiment_polarity</td>\n",
       "      <td>0.012525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>data_channel_is_socmed</td>\n",
       "      <td>0.014007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n_tokens_content</td>\n",
       "      <td>0.014419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>global_subjectivity</td>\n",
       "      <td>0.014432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n_unique_tokens</td>\n",
       "      <td>0.015276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>kw_min_max</td>\n",
       "      <td>0.017555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>kw_avg_min</td>\n",
       "      <td>0.018747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>self_reference_max_shares</td>\n",
       "      <td>0.019181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>kw_avg_max</td>\n",
       "      <td>0.019576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>num_hrefs</td>\n",
       "      <td>0.019738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>LDA_00</td>\n",
       "      <td>0.019918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>weekday_is_saturday</td>\n",
       "      <td>0.020695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>LDA_01</td>\n",
       "      <td>0.020747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>LDA_04</td>\n",
       "      <td>0.027757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>n_non_stop_unique_tokens</td>\n",
       "      <td>0.029353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>kw_min_avg</td>\n",
       "      <td>0.035260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>is_weekend</td>\n",
       "      <td>0.036068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>self_reference_avg_sharess</td>\n",
       "      <td>0.037931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>timedelta</td>\n",
       "      <td>0.038964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>LDA_02</td>\n",
       "      <td>0.040674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>data_channel_is_world</td>\n",
       "      <td>0.049771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>kw_max_avg</td>\n",
       "      <td>0.050025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>data_channel_is_entertainment</td>\n",
       "      <td>0.053896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>self_reference_min_shares</td>\n",
       "      <td>0.066857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>kw_avg_avg</td>\n",
       "      <td>0.119393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           feature  importance\n",
       "4    n_non_stop_words               0.000000  \n",
       "30   weekday_is_monday              0.000394  \n",
       "31   weekday_is_tuesday             0.000398  \n",
       "32   weekday_is_wednesday           0.000411  \n",
       "34   weekday_is_friday              0.000511  \n",
       "33   weekday_is_thursday            0.000614  \n",
       "12   data_channel_is_lifestyle      0.000911  \n",
       "18   kw_min_min                     0.002676  \n",
       "53   min_negative_polarity          0.002785  \n",
       "51   max_positive_polarity          0.003009  \n",
       "14   data_channel_is_bus            0.003217  \n",
       "57   abs_title_subjectivity         0.003236  \n",
       "1    n_tokens_title                 0.003290  \n",
       "58   abs_title_sentiment_polarity   0.004017  \n",
       "9    num_videos                     0.004442  \n",
       "11   num_keywords                   0.004463  \n",
       "56   title_sentiment_polarity       0.004822  \n",
       "55   title_subjectivity             0.005407  \n",
       "7    num_self_hrefs                 0.005438  \n",
       "54   max_negative_polarity          0.005970  \n",
       "36   weekday_is_sunday              0.006597  \n",
       "47   rate_positive_words            0.006879  \n",
       "50   min_positive_polarity          0.007158  \n",
       "22   kw_max_max                     0.007160  \n",
       "46   global_rate_negative_words     0.007863  \n",
       "8    num_imgs                       0.008034  \n",
       "41   LDA_03                         0.009817  \n",
       "19   kw_max_min                     0.009992  \n",
       "45   global_rate_positive_words     0.010077  \n",
       "52   avg_negative_polarity          0.010291  \n",
       "49   avg_positive_polarity          0.011230  \n",
       "10   average_token_length           0.011330  \n",
       "16   data_channel_is_tech           0.012302  \n",
       "48   rate_negative_words            0.012495  \n",
       "44   global_sentiment_polarity      0.012525  \n",
       "15   data_channel_is_socmed         0.014007  \n",
       "2    n_tokens_content               0.014419  \n",
       "43   global_subjectivity            0.014432  \n",
       "3    n_unique_tokens                0.015276  \n",
       "21   kw_min_max                     0.017555  \n",
       "20   kw_avg_min                     0.018747  \n",
       "28   self_reference_max_shares      0.019181  \n",
       "23   kw_avg_max                     0.019576  \n",
       "6    num_hrefs                      0.019738  \n",
       "38   LDA_00                         0.019918  \n",
       "35   weekday_is_saturday            0.020695  \n",
       "39   LDA_01                         0.020747  \n",
       "42   LDA_04                         0.027757  \n",
       "5    n_non_stop_unique_tokens       0.029353  \n",
       "24   kw_min_avg                     0.035260  \n",
       "37   is_weekend                     0.036068  \n",
       "29   self_reference_avg_sharess     0.037931  \n",
       "0    timedelta                      0.038964  \n",
       "40   LDA_02                         0.040674  \n",
       "17   data_channel_is_world          0.049771  \n",
       "25   kw_max_avg                     0.050025  \n",
       "13   data_channel_is_entertainment  0.053896  \n",
       "27   self_reference_min_shares      0.066857  \n",
       "26   kw_avg_avg                     0.119393  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------\n",
      "Times for Training, Prediction: 6.11491, 0.03302\n",
      "Accuracy for Training, Test sets: 0.70404, 0.66050\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "results,learner = randomForest(X_train, X_test, y_train, y_test)\n",
    "featureImp = pd.DataFrame(columns=['feature','importance'])\n",
    "featureImp['feature'] = features.columns\n",
    "featureImp['importance'] = learner.feature_importances_\n",
    "featureImp = featureImp.sort_values(by='importance')\n",
    "display(featureImp)\n",
    "print (\"-----------------------------------------------------------------------\")\n",
    "print (\"Times for Training, Prediction: %.5f, %.5f\" %(results['train_time'], results['pred_time']))    \n",
    "print (\"Accuracy for Training, Test sets: %.5f, %.5f\" %(results['acc_train'], results['acc_test']))     \n",
    "print (\"-----------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement Principal component analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement the PCA with 6 dimensions\n",
    "dim = 6\n",
    "reduced_f, pca_comp = pca(features,dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement Gaussian mixture clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------\n",
      "silhouette score for GMM: 0.3677\n",
      "Optimal number of components: 10.0000\n",
      "number of centers: 10.0000\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      "silhouette score for GMM: 0.5086\n",
      "Optimal number of components: 20.0000\n",
      "number of centers: 20.0000\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      "silhouette score for GMM: 0.5000\n",
      "Optimal number of components: 30.0000\n",
      "number of centers: 30.0000\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      "silhouette score for GMM: 0.4381\n",
      "Optimal number of components: 40.0000\n",
      "number of centers: 40.0000\n",
      "-----------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Clustering scores')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clus_df = pd.DataFrame(columns=['clusters','score'])\n",
    "clist = [10,20,30,40]; slist = [];\n",
    "for dim in clist:\n",
    "    cluster, centers, score = gclus(reduced_f,dim)\n",
    "    slist.append(score * 100)\n",
    "    print (\"-----------------------------------------------------------------------\")\n",
    "    print \"silhouette score for GMM: {:.4f}\".format(score)\n",
    "    print \"Optimal number of components: {:.4f}\".format(cluster.n_components)\n",
    "    print \"number of centers: {:.4f}\".format(len(centers))\n",
    "    print (\"-----------------------------------------------------------------------\")\n",
    "\n",
    "clus_df['clusters'] = clist\n",
    "clus_df['score'] = slist\n",
    "\n",
    "ax = sns.barplot(x=\"clusters\", y=\"score\", data=clus_df)\n",
    "ax.set_title('Clustering scores')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('test.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
